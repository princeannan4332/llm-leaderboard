Model Name,MCQ Accuracy,MCQ BertScore F1,MCQ Avg Rouge,SAQ BertScore F1,SAQ Avg Rouge,Consumer Queries BertScore F1,Consumer Queries Avg Rouge
GPT-4o,0.7427,0.861,0.2256,,,,
Claude 3 Opus,0.763,0.8572,0.2181,,,,
Gemini Ultra,0.808 (0.8063),0.875 (0.8752),0.2519 (0.2535),,,,
Gemini pro,. (0.7013),. (0.8725),. (0.2548),,,,
MedLM,0.7013 (0.6993),0.8725 (0.8732),0.2548 (0.2585),,,,
MedPalm 2,. (0.751),. (0.8708),. (0.2474),,,,
Meta-Llama-3-70B-Instruct,0.78.12,,,,,,
OpenBioLLM-70B,0.78.91,,,,,,
